{
  "name": "llm-express-config",
  "version": "0.1.0",
  "description": "Express middleware for LLM-powered HTTP configuration generation",
  "exports": {
    ".": {
      "import": {
        "types": "./dist/esm/index.d.ts",
        "default": "./dist/esm/index.js"
      },
      "require": {
        "types": "./dist/cjs/index.d.cts",
        "default": "./dist/cjs/index.cjs"
      }
    },
    "./package.json": "./package.json"
  },
  "type": "module",
  "main": "dist/cjs/index.cjs",
  "module": "dist/esm/index.js",
  "types": "dist/esm/index.d.ts",
  "scripts": {
    "test:build": "vite build && vitest && publint --strict"
  },
  "files": [
    "dist"
  ],
  "keywords": [
    "express",
    "llm",
    "middleware",
    "openai"
  ],
  "author": "",
  "license": "MIT",
  "peerDependencies": {
    "express": "^4.x",
    "openai": "^4.x"
  },
  "devDependencies": {
    "@tanstack/config": "^0.15.0",
    "@types/express": "^4.17.17",
    "@types/jest": "^29.5.14",
    "@types/supertest": "^6.0.2",
    "jest": "^29.7.0",
    "supertest": "^7.0.0",
    "ts-jest": "^29.2.5",
    "typescript": "^5.0.0"
  },
  "dependencies": {
    "@anthropic-ai/sdk": "^0.33.1"
  }
}
